# llama-node

<center><h2>Large Language Model LLaMA on node.js</h2></center>

<center><h3><a href="http://llama-node.vercel.app/">Official Documentations</a></h3></center>

<center>
<img alt="GitHub Workflow Status" src="https://img.shields.io/github/actions/workflow/status/hlhr202/llama-node/llama-build.yml">
<img alt="MIT" src="https://img.shields.io/github/license/Atome-FE/llama-node">
<a href="https://www.npmjs.com/package/llama-node"><img alt="npm" src="https://img.shields.io/npm/v/llama-node"></a>
<a href="https://www.npmjs.com/package/llama-node"><img alt="npm type definitions" src="https://img.shields.io/npm/types/llama-node"></a>
<a href="https://twitter.com/hlhr202"><img alt="twitter" src="https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fhlhr202"></a>
</center>

<center><img src="./doc/assets/llama.png" width="300px" height="300px" alt="LLaMA generated by Stable diffusion"/></center>

<sub>Picture generated by stable diffusion.</sub>

---

- [llama-node](#llama-node)
  - [Introduction](#introduction)
  - [Install](#install)
  - [Performance related](#performance-related)
    - [Manual compilation](#manual-compilation)

---

## Introduction

This is a nodejs client library for llama (or llama based) LLM built on top of [llama-rs](https://github.com/rustformers/llama-rs) and [llama.cpp](https://github.com/ggerganov/llama.cpp). It uses [napi-rs](https://github.com/napi-rs/napi-rs) for channel messages between node.js and llama thread.

This project is in an early stage, the API for nodejs may change in the future, use it with caution.

From v0.0.21, both llama-rs and llama.cpp backends are supported!

Currently supported platforms:
- darwin-x64
- darwin-arm64
- linux-x64-gnu (glibc >= 2.31)
- linux-x64-musl
- win32-x64-msvc

Node.js version: >= 16

---

## Install

- Install main package
```bash
npm install llama-node
```

- Install llama-rs backend
```bash
npm install @llama-node/core
```

- Install llama.cpp backend
```bash
npm install @llama-node/llama-cpp
```

---

## Performance related

We provide prebuild binaries for linux-x64, win32-x64, apple-x64, apple-silicon. For other platforms, before you install the npm package, please install rust environment for self built.

Due to complexity of cross compilation, it is hard for pre-building a binary that fits all platform needs with best performance.

If you face low performance issue, I would strongly suggest you do a manual compilation. Otherwise you have to wait for a better pre-compiled native binding. I am trying to investigate the way to produce a matrix of multi-platform supports.

### Manual compilation

WIP

---